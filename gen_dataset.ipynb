{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "564f312f-612c-4c6e-a07b-cddc961528cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import glob\n",
    "import json\n",
    "import datasets as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "635b8371-ce67-405b-abe0-a33f30e779e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/maryam.sana/anaconda3/envs/compressai/lib/python3.12/site-packages/transformers/models/llava/configuration_llava.py:104: FutureWarning: The `vocab_size` argument is deprecated and will be removed in v4.42, since it can be inferred from the `text_config`. Passing this argument has no effect\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████████| 3/3 [00:02<00:00,  1.17it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = LlavaForConditionalGeneration.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n",
    "processor = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cc308e2-90d6-4bb9-803a-85d16bfa14a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_caption(frame):\n",
    "    prompt = \"<image>\\nUSER:Give a detailed visual description of this image ?\\nASSISTANT:\"\n",
    "    inputs = processor(text=prompt, images=frame, return_tensors=\"pt\")\n",
    "    generate_ids = model.generate(**inputs, max_length=200)\n",
    "    caption_llava = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "    return caption_llava.split('ASSISTANT:')[1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc06d5e8-0b68-4dc5-b8c7-544bcbcb943a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata file created successfully.\n"
     ]
    }
   ],
   "source": [
    "img_files = sorted(glob.glob('data/Jockey/*.png'))\n",
    "output_directory = 'data/custom_data/train/'\n",
    "# Open a new JSON Lines file to write the metadata\n",
    "with open('data/custom_data/train/metadata.jsonl', 'w') as file:\n",
    "    for i, img_path in enumerate(img_files[0:10]):\n",
    "        frame = Image.open(img_path)\n",
    "        caption = get_caption(frame)\n",
    "        new_img_path = f\"{output_directory}{os.path.basename(img_path)}\"\n",
    "        # frame.save(new_img_path)\n",
    "\n",
    "        # Prepare the dictionary to write into JSONL\n",
    "        data = {\n",
    "            \"file_name\": new_img_path.split('/')[-1],  # Extract filename from path\n",
    "            \"text\": caption\n",
    "        }\n",
    "\n",
    "        # Write the JSON data to the file\n",
    "        json.dump(data, file)\n",
    "        file.write('\\n')  # Newline for the next entry\n",
    "\n",
    "print(\"Metadata file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0dd216f-22c8-4715-8c90-d7ebd20759f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds.load_dataset(\"imagefolder\", data_dir='data/custom_data/', split=\"train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
